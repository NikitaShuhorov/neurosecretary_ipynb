{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0d7cb0fb-6708-47fe-88fb-f8af40e44073",
      "metadata": {
        "id": "0d7cb0fb-6708-47fe-88fb-f8af40e44073"
      },
      "source": [
        "# # –ù–µ–π—Ä–æ-—Å–µ–∫—Ä–µ—Ç–∞—Ä—å: Telegram-–±–æ—Ç –¥–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ —Å–æ–≤–µ—â–∞–Ω–∏–π\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rKaqM0g7Aigm",
      "metadata": {
        "id": "rKaqM0g7Aigm"
      },
      "source": [
        "# ## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ä–µ–¥—ã\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–≠—Ç–æ—Ç –±–ª–æ–∫ –∫–æ–¥–∞ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –ø–æ–¥–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –º–µ–∂–¥—É –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ –∏ —É–±—Ä–∞—Ç—å –ª–∏—à–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ª–æ–≥–∞—Ö, —á—Ç–æ –¥–µ–ª–∞–µ—Ç —Ä–∞–±–æ—Ç—É –±–æ—Ç–∞ –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –∏ —á–∏—Å—Ç–æ–π."
      ],
      "metadata": {
        "id": "QnVjnZmkzp18"
      },
      "id": "QnVjnZmkzp18"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "# –ü–æ–¥–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è\n",
        "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "TvHpkWC8TwWV"
      },
      "id": "TvHpkWC8TwWV",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bBfWCsqWufBA",
      "metadata": {
        "id": "bBfWCsqWufBA"
      },
      "source": [
        "# ## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "# –í—ã–ø–æ–ª–Ω–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e33f5028-d51b-4e13-bd84-8a39fcde5d91",
      "metadata": {
        "id": "e33f5028-d51b-4e13-bd84-8a39fcde5d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa45be7f-3b3f-4040-c76e-0da6a1957e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/171.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.4/171.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m669.5/669.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q python-telegram-bot openai yt-dlp whisper noisereduce soundfile numpy tqdm pydub nest_asyncio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U6XVkklJzwc2"
      },
      "id": "U6XVkklJzwc2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ó—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ–º–æ–≥–∞–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–µ–π –∏ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ API, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–æ –±–æ–ª–µ–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏.**"
      ],
      "metadata": {
        "id": "5xvP6Qb-1QSp"
      },
      "id": "5xvP6Qb-1QSp"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "stI3_nJgdBIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0f0d65-2c0f-429d-e0b0-a00a6cc38600"
      },
      "id": "stI3_nJgdBIj",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d85f23ee",
      "metadata": {
        "id": "d85f23ee"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y ffmpeg > /dev/null  # –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "D3ff_qQUyyew",
      "metadata": {
        "id": "D3ff_qQUyyew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eedb6a51-e043-42fb-df30-8ece477c5b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-dgi3f1dl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-dgi3f1dl\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.61.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2->openai-whisper==20240930) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=38525fd66cc6bfb4cc7aa55d770c37a4170ddb0d7c5c2a38fc07b7c04e963f87\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lsrvuh6q/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git # –î–ª—è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "281d6575-2256-433d-8f31-61f6c1ca50e6",
      "metadata": {
        "id": "281d6575-2256-433d-8f31-61f6c1ca50e6"
      },
      "source": [
        "# ## –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e2df2034-a556-43ed-94d7-b7fe6e0774a1",
      "metadata": {
        "id": "e2df2034-a556-43ed-94d7-b7fe6e0774a1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import warnings\n",
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "from getpass import getpass\n",
        "\n",
        "import openai\n",
        "import whisper\n",
        "import yt_dlp\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b5d9f8-3dfb-4a9b-998c-4f5adad2b386",
      "metadata": {
        "id": "72b5d9f8-3dfb-4a9b-998c-4f5adad2b386"
      },
      "source": [
        "# ## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7b11c95d-7d1d-414f-972a-27cf29b73241",
      "metadata": {
        "id": "7b11c95d-7d1d-414f-972a-27cf29b73241"
      },
      "outputs": [],
      "source": [
        "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
        "@dataclass\n",
        "class Config:\n",
        "    TELEGRAM_TOKEN: str\n",
        "    OPENAI_API_KEY: str\n",
        "    WHISPER_MODEL: str = \"base\"\n",
        "    GPT_MODEL: str = \"gpt-4-turbo\"\n",
        "    AUDIO_CACHE: str = \"audio_cache\"\n",
        "    MAX_FILE_SIZE_MB: int = 50\n",
        "    TEMP_ANALYSIS: float = 0.2\n",
        "    TEMP_PROTOCOL: float = 0.5\n",
        "    SUPPORTED_FORMATS: tuple = ('wav', 'mp3', 'ogg', 'flac')\n",
        "\n",
        "    def __post_init__(self):\n",
        "        os.makedirs(self.AUDIO_CACHE, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ZQRXw5a-aZY",
      "metadata": {
        "id": "7ZQRXw5a-aZY"
      },
      "source": [
        "# ## –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "jF6BT1S2-dV1",
      "metadata": {
        "id": "jF6BT1S2-dV1"
      },
      "outputs": [],
      "source": [
        "# –ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ\n",
        "class AudioProcessor:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(\"AudioProcessor\")\n",
        "\n",
        "    async def process_input(self, update: Update, input_source: str) -> tuple:\n",
        "        \"\"\"\n",
        "        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–≤–æ–¥–∞: –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏–∑ Telegram –∏–ª–∏ —Å—Å—ã–ª–∫–∞ –Ω–∞ YouTube,\n",
        "        —Å–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –µ–≥–æ –≤ WAV (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è).\n",
        "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (–ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É, —Ç–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞).\n",
        "        \"\"\"\n",
        "        if update.message.audio:\n",
        "            try:\n",
        "                # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç —Ñ–∞–π–ª–∞ –∏ —Å–∫–∞—á–∏–≤–∞–µ–º –µ–≥–æ\n",
        "                tg_file = await update.message.audio.get_file()\n",
        "                file_path = os.path.join(self.config.AUDIO_CACHE, f\"{tg_file.file_id}.mp3\")\n",
        "                await tg_file.download_to_drive(custom_path=file_path)\n",
        "                source_type = \"telegram\"\n",
        "                self.logger.info(\"–ê—É–¥–∏–æ—Ñ–∞–π–ª –∏–∑ Telegram —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.\")\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}\")\n",
        "                raise Exception(\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –∏–∑ Telegram.\")\n",
        "        elif update.message.text:\n",
        "            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Å—ã–ª–∫—É –Ω–∞ YouTube\n",
        "            if \"youtube.com\" in input_source or \"youtu.be\" in input_source:\n",
        "                source_type = \"youtube\"\n",
        "                file_path = await self.download_youtube_audio(input_source)\n",
        "            else:\n",
        "                raise Exception(\"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ YouTube.\")\n",
        "        else:\n",
        "            raise Exception(\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–≤–æ–¥–∞.\")\n",
        "\n",
        "        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –≤ WAV, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è\n",
        "        if not file_path.lower().endswith('.wav'):\n",
        "            wav_path = await self._convert_to_wav(file_path)\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "            except Exception:\n",
        "                pass  # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å, –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º\n",
        "            file_path = wav_path\n",
        "\n",
        "        return file_path, source_type\n",
        "\n",
        "    async def _convert_to_wav(self, input_path: str) -> str:\n",
        "        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç WAV —Å –ø–æ–º–æ—â—å—é pydub\"\"\"\n",
        "        try:\n",
        "            output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
        "            audio = AudioSegment.from_file(input_path)\n",
        "            audio.export(output_path, format=\"wav\")\n",
        "            self.logger.info(\"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}\")\n",
        "            raise Exception(\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ –≤ WAV —Ñ–æ—Ä–º–∞—Ç.\")\n",
        "\n",
        "    async def download_youtube_audio(self, url: str) -> str:\n",
        "        \"\"\"–°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ —Å YouTube —Å –ø–æ–º–æ—â—å—é yt_dlp\"\"\"\n",
        "        try:\n",
        "            ydl_opts = {\n",
        "                'format': 'bestaudio/best',\n",
        "                'outtmpl': os.path.join(self.config.AUDIO_CACHE, '%(id)s.%(ext)s'),\n",
        "                'quiet': True,\n",
        "                'no_warnings': True,\n",
        "            }\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(url, download=True)\n",
        "                file_path = ydl.prepare_filename(info)\n",
        "            self.logger.info(\"–ê—É–¥–∏–æ —Å YouTube —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ.\")\n",
        "            return file_path\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞—É–¥–∏–æ —Å YouTube: {e}\")\n",
        "            raise Exception(\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∞—É–¥–∏–æ —Å YouTube.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LKNYPpRS-scO",
      "metadata": {
        "id": "LKNYPpRS-scO"
      },
      "source": [
        "# ## –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "vrArOqk2-ti6",
      "metadata": {
        "id": "vrArOqk2-ti6"
      },
      "outputs": [],
      "source": [
        "class MeetingProcessor:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.whisper_model = whisper.load_model(config.WHISPER_MODEL)\n",
        "        openai.api_key = config.OPENAI_API_KEY\n",
        "        self.logger = logging.getLogger(\"MeetingProcessor\")\n",
        "\n",
        "    async def process_meeting(self, audio_path: str) -> str:\n",
        "        \"\"\"\n",
        "        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ Whisper –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª –≤—Å—Ç—Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é GPT.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"–ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ...\")\n",
        "            result = self.whisper_model.transcribe(audio_path)\n",
        "            transcription = result.get(\"text\", \"\")\n",
        "            self.logger.info(\"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
        "\n",
        "            protocol = self.generate_protocol(transcription)\n",
        "            return protocol\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å—Ç—Ä–µ—á–∏: {e}\")\n",
        "            raise Exception(\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ.\")\n",
        "\n",
        "    def generate_protocol(self, transcription: str) -> str:\n",
        "        \"\"\"\n",
        "        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ OpenAI GPT –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Å–æ–≤–µ—â–∞–Ω–∏—è.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            prompt = f\"–°–æ–∑–¥–∞–π –ø—Ä–æ—Ç–æ–∫–æ–ª —Å–æ–≤–µ—â–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏:\\n\\n{transcription}\"\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=self.config.GPT_MODEL,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª—ã —Å–æ–≤–µ—â–∞–Ω–∏–π.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.5,\n",
        "            )\n",
        "            protocol = response.choices[0].message.content.strip()\n",
        "            return protocol\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {e}\")\n",
        "            raise Exception(\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uZZCBMJp-zoo",
      "metadata": {
        "id": "uZZCBMJp-zoo"
      },
      "source": [
        "# ## Telegram Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "lXuETDeJ-2br",
      "metadata": {
        "id": "lXuETDeJ-2br"
      },
      "outputs": [],
      "source": [
        "# –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å Telegram-–±–æ—Ç–∞\n",
        "class NeuroSecretaryBot:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.audio_processor = AudioProcessor(config)\n",
        "        self.meeting_processor = MeetingProcessor(config)\n",
        "        self.app = Application.builder().token(config.TELEGRAM_TOKEN).build()\n",
        "\n",
        "        self.app.add_handler(CommandHandler(\"start\", self.start))\n",
        "        self.app.add_handler(MessageHandler(filters.AUDIO | filters.TEXT, self.handle_input))\n",
        "\n",
        "        logging.basicConfig(\n",
        "            format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "            level=logging.INFO\n",
        "        )\n",
        "        self.logger = logging.getLogger(\"Bot\")\n",
        "\n",
        "    async def start(self, update: Update, context):\n",
        "        await update.message.reply_text(\n",
        "            \"ü§ñ –ù–µ–π—Ä–æ-—Å–µ–∫—Ä–µ—Ç–∞—Ä—å –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!\\n\\n\"\n",
        "            \"–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª (MP3/WAV/OOG) –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ YouTube –≤–∏–¥–µ–æ\"\n",
        "        )\n",
        "\n",
        "    async def handle_input(self, update: Update, context):\n",
        "        message = await update.message.reply_text(\"üîÑ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏...\")\n",
        "        try:\n",
        "            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –≤–≤–æ–¥–∞\n",
        "            if update.message.audio:\n",
        "                input_source = update.message.audio.file_id\n",
        "            elif update.message.text:\n",
        "                input_source = update.message.text\n",
        "            else:\n",
        "                await message.edit_text(\"‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç\")\n",
        "                return\n",
        "\n",
        "            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ/—Å—Å—ã–ª–∫–∏\n",
        "            await message.edit_text(\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\")\n",
        "            audio_path, source_type = await self.audio_processor.process_input(update, input_source)\n",
        "\n",
        "            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –≤—Å—Ç—Ä–µ—á–∏\n",
        "            await message.edit_text(\"üîç –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ...\")\n",
        "            protocol = await self.meeting_processor.process_meeting(audio_path)\n",
        "\n",
        "            # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "            prefix = \"üé• YouTube: \" if source_type == \"youtube\" else \"‚úÖ –ì–æ—Ç–æ–≤–æ:\"\n",
        "            await message.edit_text(f\"{prefix}\\n\\n{protocol}\")\n",
        "\n",
        "            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n",
        "            if os.path.exists(audio_path):\n",
        "                os.remove(audio_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            await message.edit_text(f\"‚ùå –û—à–∏–±–∫–∞: {str(e)}\")\n",
        "            self.logger.error(f\"Main Error: {str(e)}\")\n",
        "\n",
        "    def run(self):\n",
        "        self.logger.info(\"–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω\")\n",
        "        self.app.run_polling()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A57tZCTI-_kw",
      "metadata": {
        "id": "A57tZCTI-_kw"
      },
      "source": [
        "# ## –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eM2Fy3Ld_B50",
      "metadata": {
        "id": "eM2Fy3Ld_B50"
      },
      "outputs": [],
      "source": [
        "# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–æ–≥—Ä–∞–º–º—É\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # –î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –≤ Jupyter –ø—Ä–∏–º–µ–Ω—è–µ–º nest_asyncio\n",
        "        import nest_asyncio\n",
        "        nest_asyncio.apply()\n",
        "\n",
        "        print(\"üîë –í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:\")\n",
        "        config = Config(\n",
        "            TELEGRAM_TOKEN=getpass(\"Telegram Token (@BotFather): \"),\n",
        "            OPENAI_API_KEY=getpass(\"OpenAI API Key (https://platform.openai.com): \")\n",
        "        )\n",
        "\n",
        "        bot = NeuroSecretaryBot(config)\n",
        "        bot.run()\n",
        "    except Exception as e:\n",
        "        print(f\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}