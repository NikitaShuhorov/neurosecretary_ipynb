{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0d7cb0fb-6708-47fe-88fb-f8af40e44073",
      "metadata": {
        "id": "0d7cb0fb-6708-47fe-88fb-f8af40e44073"
      },
      "source": [
        "# # Нейро-секретарь: Telegram-бот для протоколов совещаний\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rKaqM0g7Aigm",
      "metadata": {
        "id": "rKaqM0g7Aigm"
      },
      "source": [
        "# ## Конфигурация среды\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот блок кода настраивает переменные окружения и подавляет предупреждения, чтобы избежать конфликтов между библиотеками и убрать лишние сообщения в логах, что делает работу бота более стабильной и чистой."
      ],
      "metadata": {
        "id": "QnVjnZmkzp18"
      },
      "id": "QnVjnZmkzp18"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "# Подавляем специфические предупреждения\n",
        "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "TvHpkWC8TwWV"
      },
      "id": "TvHpkWC8TwWV",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bBfWCsqWufBA",
      "metadata": {
        "id": "bBfWCsqWufBA"
      },
      "source": [
        "# ## Установка зависимостей\n",
        "# Выполните эту ячейку для установки необходимых библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e33f5028-d51b-4e13-bd84-8a39fcde5d91",
      "metadata": {
        "id": "e33f5028-d51b-4e13-bd84-8a39fcde5d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa45be7f-3b3f-4040-c76e-0da6a1957e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/171.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m143.4/171.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.5/669.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q python-telegram-bot openai yt-dlp whisper noisereduce soundfile numpy tqdm pydub nest_asyncio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U6XVkklJzwc2"
      },
      "id": "U6XVkklJzwc2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Зта установка помогает избежать несовместимостей и неожиданных изменений в API, которые могут возникнуть при обновлении до более новой версии.**"
      ],
      "metadata": {
        "id": "5xvP6Qb-1QSp"
      },
      "id": "5xvP6Qb-1QSp"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "stI3_nJgdBIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0f0d65-2c0f-429d-e0b0-a00a6cc38600"
      },
      "id": "stI3_nJgdBIj",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d85f23ee",
      "metadata": {
        "id": "d85f23ee"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y ffmpeg > /dev/null  # Для обработки аудио"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "D3ff_qQUyyew",
      "metadata": {
        "id": "D3ff_qQUyyew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eedb6a51-e043-42fb-df30-8ece477c5b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-dgi3f1dl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-dgi3f1dl\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.61.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton>=2->openai-whisper==20240930) (3.17.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.44.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803669 sha256=38525fd66cc6bfb4cc7aa55d770c37a4170ddb0d7c5c2a38fc07b7c04e963f87\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lsrvuh6q/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git # Для Транскрибации аудиофайлов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "281d6575-2256-433d-8f31-61f6c1ca50e6",
      "metadata": {
        "id": "281d6575-2256-433d-8f31-61f6c1ca50e6"
      },
      "source": [
        "# ## Импорт библиотек и настройка окружения\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e2df2034-a556-43ed-94d7-b7fe6e0774a1",
      "metadata": {
        "id": "e2df2034-a556-43ed-94d7-b7fe6e0774a1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import warnings\n",
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "from getpass import getpass\n",
        "\n",
        "import openai\n",
        "import whisper\n",
        "import yt_dlp\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "from telegram import Update\n",
        "from telegram.ext import Application, CommandHandler, MessageHandler, filters\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72b5d9f8-3dfb-4a9b-998c-4f5adad2b386",
      "metadata": {
        "id": "72b5d9f8-3dfb-4a9b-998c-4f5adad2b386"
      },
      "source": [
        "# ## Конфигурация системы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7b11c95d-7d1d-414f-972a-27cf29b73241",
      "metadata": {
        "id": "7b11c95d-7d1d-414f-972a-27cf29b73241"
      },
      "outputs": [],
      "source": [
        "# Конфигурация\n",
        "@dataclass\n",
        "class Config:\n",
        "    TELEGRAM_TOKEN: str\n",
        "    OPENAI_API_KEY: str\n",
        "    WHISPER_MODEL: str = \"base\"\n",
        "    GPT_MODEL: str = \"gpt-4-turbo\"\n",
        "    AUDIO_CACHE: str = \"audio_cache\"\n",
        "    MAX_FILE_SIZE_MB: int = 50\n",
        "    TEMP_ANALYSIS: float = 0.2\n",
        "    TEMP_PROTOCOL: float = 0.5\n",
        "    SUPPORTED_FORMATS: tuple = ('wav', 'mp3', 'ogg', 'flac')\n",
        "\n",
        "    def __post_init__(self):\n",
        "        os.makedirs(self.AUDIO_CACHE, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ZQRXw5a-aZY",
      "metadata": {
        "id": "7ZQRXw5a-aZY"
      },
      "source": [
        "# ## Обработка аудио с прогресс-баром\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "jF6BT1S2-dV1",
      "metadata": {
        "id": "jF6BT1S2-dV1"
      },
      "outputs": [],
      "source": [
        "# Класс для обработки аудио\n",
        "class AudioProcessor:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.logger = logging.getLogger(\"AudioProcessor\")\n",
        "\n",
        "    async def process_input(self, update: Update, input_source: str) -> tuple:\n",
        "        \"\"\"\n",
        "        Определяет источник ввода: аудиофайл из Telegram или ссылка на YouTube,\n",
        "        скачивает аудио и конвертирует его в WAV (если требуется).\n",
        "        Возвращает кортеж (путь к аудиофайлу, тип источника).\n",
        "        \"\"\"\n",
        "        if update.message.audio:\n",
        "            try:\n",
        "                # Получаем объект файла и скачиваем его\n",
        "                tg_file = await update.message.audio.get_file()\n",
        "                file_path = os.path.join(self.config.AUDIO_CACHE, f\"{tg_file.file_id}.mp3\")\n",
        "                await tg_file.download_to_drive(custom_path=file_path)\n",
        "                source_type = \"telegram\"\n",
        "                self.logger.info(\"Аудиофайл из Telegram успешно загружен.\")\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Ошибка загрузки файла: {e}\")\n",
        "                raise Exception(\"Ошибка при загрузке аудиофайла из Telegram.\")\n",
        "        elif update.message.text:\n",
        "            # Если текст содержит ссылку на YouTube\n",
        "            if \"youtube.com\" in input_source or \"youtu.be\" in input_source:\n",
        "                source_type = \"youtube\"\n",
        "                file_path = await self.download_youtube_audio(input_source)\n",
        "            else:\n",
        "                raise Exception(\"Неподдерживаемый формат. Отправьте аудиофайл или ссылку на YouTube.\")\n",
        "        else:\n",
        "            raise Exception(\"Не удалось определить источник ввода.\")\n",
        "\n",
        "        # Если файл не в WAV, выполняется конвертация\n",
        "        if not file_path.lower().endswith('.wav'):\n",
        "            wav_path = await self._convert_to_wav(file_path)\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "            except Exception:\n",
        "                pass  # Если не удалось удалить, просто продолжаем\n",
        "            file_path = wav_path\n",
        "\n",
        "        return file_path, source_type\n",
        "\n",
        "    async def _convert_to_wav(self, input_path: str) -> str:\n",
        "        \"\"\"Конвертация аудио в формат WAV с помощью pydub\"\"\"\n",
        "        try:\n",
        "            output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
        "            audio = AudioSegment.from_file(input_path)\n",
        "            audio.export(output_path, format=\"wav\")\n",
        "            self.logger.info(\"Конвертация в WAV завершена.\")\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Ошибка конвертации: {e}\")\n",
        "            raise Exception(\"Ошибка при конвертации аудио в WAV формат.\")\n",
        "\n",
        "    async def download_youtube_audio(self, url: str) -> str:\n",
        "        \"\"\"Скачивает аудио с YouTube с помощью yt_dlp\"\"\"\n",
        "        try:\n",
        "            ydl_opts = {\n",
        "                'format': 'bestaudio/best',\n",
        "                'outtmpl': os.path.join(self.config.AUDIO_CACHE, '%(id)s.%(ext)s'),\n",
        "                'quiet': True,\n",
        "                'no_warnings': True,\n",
        "            }\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(url, download=True)\n",
        "                file_path = ydl.prepare_filename(info)\n",
        "            self.logger.info(\"Аудио с YouTube успешно загружено.\")\n",
        "            return file_path\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Ошибка при загрузке аудио с YouTube: {e}\")\n",
        "            raise Exception(\"Ошибка при загрузке аудио с YouTube.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LKNYPpRS-scO",
      "metadata": {
        "id": "LKNYPpRS-scO"
      },
      "source": [
        "# ## Обработка текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "vrArOqk2-ti6",
      "metadata": {
        "id": "vrArOqk2-ti6"
      },
      "outputs": [],
      "source": [
        "class MeetingProcessor:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.whisper_model = whisper.load_model(config.WHISPER_MODEL)\n",
        "        openai.api_key = config.OPENAI_API_KEY\n",
        "        self.logger = logging.getLogger(\"MeetingProcessor\")\n",
        "\n",
        "    async def process_meeting(self, audio_path: str) -> str:\n",
        "        \"\"\"\n",
        "        Транскрибирует аудио с помощью модели Whisper и генерирует протокол встречи с помощью GPT.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Начало транскрипции аудио...\")\n",
        "            result = self.whisper_model.transcribe(audio_path)\n",
        "            transcription = result.get(\"text\", \"\")\n",
        "            self.logger.info(\"Транскрипция завершена.\")\n",
        "\n",
        "            protocol = self.generate_protocol(transcription)\n",
        "            return protocol\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Ошибка обработки встречи: {e}\")\n",
        "            raise Exception(\"Ошибка при обработке аудио.\")\n",
        "\n",
        "    def generate_protocol(self, transcription: str) -> str:\n",
        "        \"\"\"\n",
        "        Отправляет транскрипцию в OpenAI GPT для генерации протокола совещания.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            prompt = f\"Создай протокол совещания на основе следующей транскрипции:\\n\\n{transcription}\"\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=self.config.GPT_MODEL,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Ты помощник, который создает протоколы совещаний.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.5,\n",
        "            )\n",
        "            protocol = response.choices[0].message.content.strip()\n",
        "            return protocol\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Ошибка генерации протокола: {e}\")\n",
        "            raise Exception(\"Ошибка при генерации протокола.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uZZCBMJp-zoo",
      "metadata": {
        "id": "uZZCBMJp-zoo"
      },
      "source": [
        "# ## Telegram Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "lXuETDeJ-2br",
      "metadata": {
        "id": "lXuETDeJ-2br"
      },
      "outputs": [],
      "source": [
        "# Основной класс Telegram-бота\n",
        "class NeuroSecretaryBot:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.audio_processor = AudioProcessor(config)\n",
        "        self.meeting_processor = MeetingProcessor(config)\n",
        "        self.app = Application.builder().token(config.TELEGRAM_TOKEN).build()\n",
        "\n",
        "        self.app.add_handler(CommandHandler(\"start\", self.start))\n",
        "        self.app.add_handler(MessageHandler(filters.AUDIO | filters.TEXT, self.handle_input))\n",
        "\n",
        "        logging.basicConfig(\n",
        "            format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "            level=logging.INFO\n",
        "        )\n",
        "        self.logger = logging.getLogger(\"Bot\")\n",
        "\n",
        "    async def start(self, update: Update, context):\n",
        "        await update.message.reply_text(\n",
        "            \"🤖 Нейро-секретарь готов к работе!\\n\\n\"\n",
        "            \"Отправьте аудиофайл (MP3/WAV/OOG) или ссылку на YouTube видео\"\n",
        "        )\n",
        "\n",
        "    async def handle_input(self, update: Update, context):\n",
        "        message = await update.message.reply_text(\"🔄 Начало обработки...\")\n",
        "        try:\n",
        "            # Определение типа ввода\n",
        "            if update.message.audio:\n",
        "                input_source = update.message.audio.file_id\n",
        "            elif update.message.text:\n",
        "                input_source = update.message.text\n",
        "            else:\n",
        "                await message.edit_text(\"❌ Неподдерживаемый формат\")\n",
        "                return\n",
        "\n",
        "            # Обработка аудио/ссылки\n",
        "            await message.edit_text(\"📥 Загрузка данных...\")\n",
        "            audio_path, source_type = await self.audio_processor.process_input(update, input_source)\n",
        "\n",
        "            # Генерация протокола встречи\n",
        "            await message.edit_text(\"🔍 Анализ содержимого...\")\n",
        "            protocol = await self.meeting_processor.process_meeting(audio_path)\n",
        "\n",
        "            # Отправка результата\n",
        "            prefix = \"🎥 YouTube: \" if source_type == \"youtube\" else \"✅ Готово:\"\n",
        "            await message.edit_text(f\"{prefix}\\n\\n{protocol}\")\n",
        "\n",
        "            # Очистка временного файла\n",
        "            if os.path.exists(audio_path):\n",
        "                os.remove(audio_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            await message.edit_text(f\"❌ Ошибка: {str(e)}\")\n",
        "            self.logger.error(f\"Main Error: {str(e)}\")\n",
        "\n",
        "    def run(self):\n",
        "        self.logger.info(\"Бот запущен\")\n",
        "        self.app.run_polling()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A57tZCTI-_kw",
      "metadata": {
        "id": "A57tZCTI-_kw"
      },
      "source": [
        "# ## Запуск бота"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eM2Fy3Ld_B50",
      "metadata": {
        "id": "eM2Fy3Ld_B50"
      },
      "outputs": [],
      "source": [
        "# Точка входа в программу\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Для корректной работы в Jupyter применяем nest_asyncio\n",
        "        import nest_asyncio\n",
        "        nest_asyncio.apply()\n",
        "\n",
        "        print(\"🔑 Введите данные для настройки:\")\n",
        "        config = Config(\n",
        "            TELEGRAM_TOKEN=getpass(\"Telegram Token (@BotFather): \"),\n",
        "            OPENAI_API_KEY=getpass(\"OpenAI API Key (https://platform.openai.com): \")\n",
        "        )\n",
        "\n",
        "        bot = NeuroSecretaryBot(config)\n",
        "        bot.run()\n",
        "    except Exception as e:\n",
        "        print(f\"Критическая ошибка: {str(e)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}